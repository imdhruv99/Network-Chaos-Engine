# Real-Time Stateful Processing Engine

## Overview

This component serves as the real-time intelligence layer for the Network Chaos Engine. Written in native Java 17 for Apache Flink, it consumes the high-throughput, chaotic network telemetry generated by the Go Producer and performs stateful stream processing to detect anomalies (like Data Exfiltration or DDoS attacks) as they happen.

Unlike standard batch processing systems that introduce artificial latency, this engine evaluates network traffic millisecond-by-millisecond. If an anomaly threshold is breached, it immediately triggers an asynchronous alert to a Discord/Slack webhook.

## Architecture & Design Decisions

I specifically chose Apache Flink (Java) leverage it's superior true-streaming capabilities.

To make this production-ready, the pipeline implements several advanced stream processing patterns:

### 1. True Streaming vs. Micro-Batching

Standard micro-batching collects data for _N_ seconds before processing it, creating artificial latency spikes. This engine processes each event the moment it arrives from Kafka, continuously evaluating the state of the network.

### 2. Event Time & Watermarks (Handling Chaos)

In real-world networks, packets arrive out of order. If Flink processes data based on when the server _received_ it (Processing Time), the aggregations will be wrong.

- **Event Time:** The engine parses the exact timestamp generated by the originating device inside the JSON payload.
- **Watermarks:** I implemented a `BoundedOutOfOrderness` watermark of 5 seconds. This tells Flink how long to wait for late-arriving packets before safely closing a time window and calculating the aggregation, ensuring accurate metrics without stalling the pipeline indefinitely.

### 3. Sliding Windows

To detect sustained attacks, the engine groups data by `src_ip` and applies a **Sliding Window** (Size: 60 seconds, Slide: 10 seconds). Instead of rigid tumbling windows (e.g., exactly 1:00 to 2:00), this calculates a continuous rolling bandwidth average, ensuring anomalies aren't hidden by being split across hard time boundaries.

### 4. Alert Fatigue & Redis Deduplication

A common pitfall in streaming alerts is spamming the on-call engineer. Because the sliding window updates every 10 seconds, a sustained 5-minute data exfiltration event would trigger 30 separate webhook alerts.

- **The Solution:** I implemented a custom Flink `RichSinkFunction` connected to a Redis cache.
- **The Logic:** Before firing the HTTP webhook, Flink checks Redis. If the alert fires, it sets a 15-minute TTL (Time-To-Live) lock (`alert:throttle:{src_ip}`). Subsequent triggers within that 15-minute window are silently dropped, completely eliminating alert fatigue.

## Prerequisites

- **Java 17** (OpenJDK)
- **Maven** (3.8+)
- Infrastructure running (Kafka, Redis) from the root `docker-compose.yml`.

## How to Build & Run

### 1. Local Development (Mini-Cluster)

When actively writing code or testing logic, you can run the Flink job directly in your terminal. This spins up a temporary local Flink environment.

```bash
cd processor
mvn clean compile exec:java
```

### 2. Production Deployment (Fat JAR)

To deploy this to the actual Dockerized Flink JobManager and TaskManager:

#### Step 1: Package the Application

- Compile the code and build a shaded "Fat JAR" containing all dependencies (Kafka connectors, Jackson, Jedis).
  ```
  mvn clean package
  ```

#### Step 2: Submit to the Cluster

- Ensure your infrastructure is running (docker-compose up -d).

- Navigate to the Flink Web UI at http://localhost:8081.

- Click Submit New Job.

- Upload processor/target/processor-1.0-SNAPSHOT.jar.

- Click Submit.

#### Step 3: Run go producer with chaos

```
EPS_TARGET=15000 WORKER_COUNT=20 CHAOS_MODE=true DATA_EXFIL_PROB=0.30 go run ./cmd/telemetry/main.go
```

## Observability & Logging

Because Flink is a distributed system, standard `System.out.println` commands do not output to the local terminal when running on a cluster.

The application utilizes SLF4J. Logs are written directly to the TaskManager nodes.

To view logs: `Go to the Flink Web UI -> Task Managers -> Click the active node -> Logs tab`.

You will see `[INFO]` logs for normal sliding window calculations and `[WARN]` logs when an anomaly breaches the threshold and fires the webhook.
